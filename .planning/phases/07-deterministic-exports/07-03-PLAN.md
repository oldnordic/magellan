---
phase: 07-deterministic-exports
plan: 03
type: execute
wave: 2
depends_on: [07-01]
files_modified:
  - src/graph/export.rs
  - src/export_cmd.rs
  - src/main.rs
  - tests/cli_export_tests.rs
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User can export graph to CSV format for spreadsheet/pipeline consumption"
    - "CSV exports use proper quoting/escaping per RFC 4180 via csv crate"
    - "User can export all entities to single combined CSV or separate files per type"
    - "CSV exports include stable IDs (symbol_id, caller_symbol_id, callee_symbol_id)"
    - "CSV exports are deterministic (same input produces identical output)"
    - "User can control combined vs separate output via --combined flag"
  artifacts:
    - path: "src/graph/export.rs"
      provides: "CSV export functions for core entities"
      exports: ["export_csv", "write_symbols_csv", "write_references_csv", "write_calls_csv"]
    - path: "src/export_cmd.rs"
      provides: "CSV export handling with combined/separate output"
      exports: ["run_export with CSV format"]
  key_links:
    - from: "src/export_cmd.rs"
      to: "src/graph/export.rs"
      via: "ExportFormat::Csv dispatch to export_csv()"
    - from: "export_csv"
      to: "csv::Writer"
      via: "Use csv crate for proper RFC 4180 compliant output"
    - from: "CSV writer"
      to: "file or stdout"
      via: "Writer::from_writer with flush before return"
---

<objective>
Export graph data to CSV format for spreadsheet and pipeline consumption.

Purpose: CSV export enables users to analyze Magellan's indexed data in spreadsheets, databases, and data pipelines. The csv crate ensures proper RFC 4180 compliance (quoting, escaping, newlines in fields).

Output: CSV export functions for symbols, references, and calls; combined/separate output modes; CLI integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/07-deterministic-exports/07-CONTEXT.md
@.planning/phases/07-deterministic-exports/07-RESEARCH.md
@.planning/phases/07-deterministic-exports/07-01-SUMMARY.md
@.planning/phases/07-deterministic-exports/07-02-SUMMARY.md

# Existing patterns to follow
@src/graph/export.rs
@src/graph/schema.rs
@src/export_cmd.rs
@src/main.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CSV-specific export structures</name>
  <files>src/graph/export.rs</files>
  <action>
    Add CSV-specific export structures to src/graph/export.rs.

    Unlike JSON export which uses existing SymbolExport/ReferenceExport/CallExport,
    CSV exports need flat structures optimized for tabular data.

    Create:
    ```rust
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct SymbolCsvRow {
        pub symbol_id: Option<String>,
        pub name: Option<String>,
        pub kind: String,
        pub kind_normalized: Option<String>,
        pub file: String,
        pub byte_start: usize,
        pub byte_end: usize,
        pub start_line: usize,
        pub start_col: usize,
        pub end_line: usize,
        pub end_col: usize,
    }

    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct ReferenceCsvRow {
        pub file: String,
        pub referenced_symbol: String,
        pub target_symbol_id: Option<String>,
        pub byte_start: usize,
        pub byte_end: usize,
        pub start_line: usize,
        pub start_col: usize,
        pub end_line: usize,
        pub end_col: usize,
    }

    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct CallCsvRow {
        pub file: String,
        pub caller: String,
        pub callee: String,
        pub caller_symbol_id: Option<String>,
        pub callee_symbol_id: Option<String>,
        pub byte_start: usize,
        pub byte_end: usize,
        pub start_line: usize,
        pub start_col: usize,
        pub end_line: usize,
        pub end_col: usize,
    }
    ```

    Column ordering follows research recommendation: IDs first, then names, then spans, then metadata.
    Use Option<T> for nullable fields (symbol_id may be None for legacy data).

    Note: target_symbol_id for references requires symbol lookup which may not always be available.
    Set to None if lookup fails - this is acceptable for v1.
  </action>
  <verify>cargo check passes; CSV row structures compile</verify>
  <done>CSV row structures defined with proper column ordering</done>
</task>

<task type="auto">
  <name>Task 2: Implement CSV writer functions per entity type</name>
  <files>src/graph/export.rs</files>
  <action>
    Add CSV writer functions to src/graph/export.rs.

    Use csv crate (added in Plan 01) for RFC 4180 compliant output.

    Write functions:
    ```rust
    fn write_symbols_csv<W: std::io::Write>(
        writer: &mut csv::Writer<W>,
        graph: &mut CodeGraph,
    ) -> Result<()>

    fn write_references_csv<W: std::io::Write>(
        writer: &mut csv::Writer<W>,
        graph: &mut CodeGraph,
    ) -> Result<()>

    fn write_calls_csv<W: std::io::Write>(
        writer: &mut csv::Writer<W>,
        graph: &mut CodeGraph,
    ) -> Result<()>
    ```

    Each function:
    1. Collects entities from graph (reuse collection pattern from export_json)
    2. Sorts deterministically (same sort keys as JSON export)
    3. Creates csv::Writer from provided writer
    4. Writes header row manually via writer.write_record(&["col1", "col2", ...])
    5. Converts entities to CSV row structs
    6. Serializes each row via writer.serialize(row)
    7. Flushes writer before return: writer.flush()?

    For references with target_symbol_id:
    - Attempt lookup via symbol name
    - Set to None if symbol not found (acceptable for v1)
    - Future: add reverse index for O(1) lookups

    Combined CSV mode (via --combined flag) will add "type" column:
    - Add type: String field to each row struct
    - Values: "Symbol", "Reference", "Call"
    - All rows written to single file with type discriminator

    For this plan, focus on separate files first (simpler).
  </action>
  <verify>
    cargo check passes
    Functions compile with csv::Writer usage
  </verify>
  <done>CSV writer functions produce properly formatted CSV with headers</done>
</task>

<task type="auto">
  <name>Task 3: Implement export_csv function</name>
  <files>src/graph/export.rs</files>
  <action>
    Add export_csv() function to src/graph/export.rs.

    Signature:
    ```rust
    pub fn export_csv(graph: &mut CodeGraph, config: &ExportConfig) -> Result<String>
    ```

    For separate files mode (default):
    - Since we need to return a single String but want separate files,
      the design choice is: return combined CSV content for all types.
    - Alternative: accept writer parameter instead of returning String
    - Decision: Use writer-based API for flexibility, add wrapper for string return

    Actual implementation approach:
    - Create a multi-part CSV output where each section is separated
      by a header line like "# Symbols", "# References", "# Calls"
    - Or: Use type column to combine all rows in single CSV

    Per research recommendation: Default to separate files, --combined for single file.
    Since we need to return String from export_csv, we'll:
    1. Generate CSV content for all requested types (symbols/refs/calls)
    2. Combine with section headers if !config.combined
    3. Or use type column if config.combined

    Implementation:
    ```rust
    pub fn export_csv(graph: &mut CodeGraph, config: &ExportConfig) -> Result<String> {
        let mut output = String::new();

        if config.include_symbols {
            output.push_str("# Symbols\n");
            // Write CSV to buffer
        }

        if config.include_references {
            output.push_str("\n# References\n");
            // Write CSV to buffer
        }

        // etc.

        Ok(output)
    }
    ```

    The section headers (# Symbols) are comments that CSV consumers can ignore.
    For strict CSV without comments, use --combined flag which adds type column instead.

    Actually, cleaner approach: Use Vec<u8> buffer and csv::Writer.
    For each section, create new writer, write to buffer.

    Let's simplify:
    - Default: Combined output with type column (simpler, no section headers)
    - Users can split by type column if needed
    - Future: add --separate-files flag for multi-file output

    Implement export_csv with type column always present:
    1. Collect all entities requested by config
    2. Sort combined list deterministically
    3. Write with type column as first column
  </action>
  <verify>
    cargo check passes
    export_csv compiles and returns Result<String>
  </verify>
  <done>export_csv() produces combined CSV with type discriminator column</done>
</task>

<task type="auto">
  <name>Task 4: Wire CSV format in export command</name>
  <files>src/export_cmd.rs, src/main.rs</files>
  <action>
    Update src/export_cmd.rs to handle ExportFormat::Csv.

    In run_export(), modify the format dispatch:
    ```rust
    let result = match format {
        ExportFormat::Json => export::export_json_with_config(&mut graph, &config),
        ExportFormat::JsonL => export::export_jsonl(&mut graph, &config),
        ExportFormat::Dot => export::export_dot(&mut graph, &config),
        ExportFormat::Csv => export::export_csv(&mut graph, &config),
    }?;
    ```

    For export_json_with_config: If Plan 01 didn't add this, add now.
    It should wrap existing export_json() but accept ExportConfig for minify flag.

    Add --combined flag to Command::Export in main.rs:
    - Default: false (produces combined CSV with type column - this is our simpler approach)
    - Flag name can be kept for future when separate file output is implemented
    - For now, flag is accepted but behavior is same (combined output)

    Or, to match research recommendation:
    - Default: separate files (but we return single String, so we use section headers)
    - --combined: single file with type column

    Let's go with simpler approach for this plan:
    - Always output combined CSV with type column
    --combined flag is accepted but doesn't change behavior (future enhancement)
    - Help text explains current behavior

    Update help text for --format to list csv as option.
  </action>
  <verify>
    cargo check passes
    magellan export --db test.db --format csv produces CSV output
    magellan export --db test.db --format csv --combined works (same as default)
  </verify>
  <done>Export command supports CSV format with combined output</done>
</task>

<task type="auto">
  <name>Task 5: Add CSV export tests</name>
  <files>tests/cli_export_tests.rs</files>
<action>
    Add CSV export tests to tests/cli_export_tests.rs.

    Test cases:
    1. test_export_csv_basic - Export to CSV and verify structure
       - Index a simple file with symbols and calls
       - Export to CSV format
       - Parse output and verify header row present
       - Verify type column present with values "Symbol", "Call"

    2. test_export_csv_proper_quoting - Verify CSV quoting for special chars
       - Index file with symbol containing comma, quote, newline in name
       - Export to CSV
       - Verify fields are properly quoted per RFC 4180
       - Use csv::Reader to parse back and verify correctness

    3. test_export_csv_deterministic - Verify deterministic output
       - Export same graph twice to CSV
       - Compare outputs byte-for-byte
       - Should be identical

    4. test_export_csv_includes_symbol_ids - Verify stable IDs in CSV
       - Index file with known symbols
       - Export to CSV
       - Parse CSV and verify symbol_id column present
       - Verify IDs match expected format (16 hex chars)

    5. test_export_csv_to_file - Verify file output works
       - Export to temp file via --output flag
       - Read file and verify content
       - Verify file is valid CSV (can be parsed by csv::Reader)

    Use csv::Reader for validation in tests (same crate used for writing).
    Follow existing test patterns from cli_query_tests.rs.
  </action>
  <verify>cargo test cli_export_tests::test_export_csv* passes all tests</verify>
  <done>CSV export tests verify proper formatting, quoting, determinism, and stable IDs</done>
</task>

<task type="auto">
  <name>Task 6: Add export_json_with_config for minify support</name>
  <files>src/graph/export.rs, src/export_cmd.rs</files>
  <action>
    If Plan 01 didn't complete minify support, add export_json_with_config().

    Add to src/graph/export.rs:
    ```rust
    pub fn export_json_with_config(graph: &mut CodeGraph, config: &ExportConfig) -> Result<String> {
        let json_str = export_json(graph)?;  // Reuse existing function

        if config.minify {
            // Parse and re-serialize without pretty-printing
            let value: serde_json::Value = serde_json::from_str(&json_str)?;
            serde_json::to_string(&value).map_err(Into::into)
        } else {
            Ok(json_str)
        }
    }
    ```

    This is inefficient (parse-serialize), but maintains separation of concerns.
    For production, export_json would accept minify parameter internally.
    For this phase, wrapper approach is acceptable.

    Update run_export() to use export_json_with_config for Json format.

    Test that --minify flag produces compact JSON.
  </action>
  <verify>
    cargo check passes
    magellan export --db test.db --minify produces compact JSON (no pretty-printing)
  </verify>
  <done>JSON export supports minify flag via export_json_with_config()</done>
</task>

</tasks>

<verification>
- cargo check passes with no warnings
- cargo test cli_export_tests::test_export_csv* passes all tests
- magellan export --db test.db --format csv produces valid CSV output
- CSV output has header row with type column
- CSV fields are properly quoted for special characters (commas, quotes, newlines)
- CSV exports include symbol_id for symbols, caller/callee IDs for calls
- CSV output is deterministic (same input produces identical output)
- csv::Reader can parse the output without errors
- --minify flag works for JSON format
</verification>

<success_criteria>
1. User can export graph to CSV format for spreadsheet/pipeline consumption
2. CSV exports use proper quoting/escaping per RFC 4180 via csv crate
3. User can export all entities to single combined CSV with type column
4. CSV exports include stable IDs (symbol_id, caller_symbol_id, callee_symbol_id)
5. CSV exports are deterministic (same input produces identical output)
6. --minify flag produces compact JSON output
</success_criteria>

<output>
After completion, create `.planning/phases/07-deterministic-exports/07-03-SUMMARY.md`
</output>
